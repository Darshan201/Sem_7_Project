{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import read_dataset as ds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "img,lbl = ds.load_mnist()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 784)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "N,H,W = img.shape\n",
    "X = np.reshape(img,(N,H*W))\n",
    "X = X.astype(np.float32)\n",
    "print(X.shape)\n",
    "Y = np.zeros((N,10))\n",
    "for i in range(N):\n",
    "    Y[i,lbl[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 784)\n"
     ]
    }
   ],
   "source": [
    "img_test,lbl_test = ds.load_mnist(dataset='testing')\n",
    "N_test,_,_ = img_test.shape\n",
    "X_test = np.reshape(img_test,(N_test,H*W))\n",
    "X_test = X_test.astype(np.float32)\n",
    "print(X_test.shape)\n",
    "Y_test = np.zeros((N,10))\n",
    "for i in range(N_test):\n",
    "    Y_test[i,lbl_test[i]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 300000\n",
    "batch_size = 64\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "#y_ = tf.nn.softmax(pred)\n",
    "prob_mine = tf.argmax(pred, 1)\n",
    "logits_mine = tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_batch(X, Y, batch_size):\n",
    "    N,_ = X.shape\n",
    "    indexes = np.random.randint(N,size=batch_size)\n",
    "    batch_x, batch_y = np.copy(X[indexes]),np.copy(Y[indexes])\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 784)\n",
      "(2, 10)\n"
     ]
    }
   ],
   "source": [
    "X_b, Y_b = get_random_batch(X,Y,2)\n",
    "print(X_b.shape)\n",
    "print(Y_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8330636.     -11737762.      -5040990.     -10039025.      -2121938.\n",
      "    -618515.6875  -4466813.5      3524141.5     17252242.      -1018084.4375]\n",
      " [  1408932.25    -9468640.       5547127.5     11276669.     -12106393.\n",
      "    3171062.75     5967064.5     -4785688.      41264488.       4330807.    ]] [8 8] 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7bc5da588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSCIIMpIIwv8ADLgrfEQ9pNYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7bc537748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step < 100:\n",
    "        batch_x,batch_y = get_random_batch(X,Y,10)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % 2 == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            '''print(\"Iter \" + str(step*2) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))'''\n",
    "        step += 1\n",
    "        #print(\"Optimization Finished!\")\n",
    "    x_test,y_test = get_random_batch(X_test,Y_test,2)\n",
    "    probs,prediction_mine,accu_mine = sess.run([pred,tf.argmax(pred,1),accuracy],feed_dict={x: x_test,y:y_test,keep_prob: 1.})\n",
    "    print(probs,prediction_mine,accu_mine)\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(np.reshape(x_test[0],(H,W)))\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(np.reshape(x_test[1],(H,W)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = get_random_batch(X, Y, batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "            x_test,y_test = get_random_batch(X_test,Y_test,256)\n",
    "            print(\"Testing Accuracy:\", \\\n",
    "                                    sess.run(accuracy, feed_dict={x: x_test,\n",
    "                                      y: y_test,\n",
    "                                      keep_prob: 1.}))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
